import os
from dotenv import load_dotenv
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from sentence_transformers import SentenceTransformer
import psycopg2

# 1. åŠ è½½ç¯å¢ƒå˜é‡ (è¯»å–å¯†ç )
load_dotenv()

# 2. æ•°æ®åº“è¿æ¥é…ç½®
DB_URL = os.getenv("DATABASE_URL")

# 3. åˆå§‹åŒ–å‘é‡æ¨¡å‹ (è¿™ä¸ªæ¨¡å‹ä¼šä¸‹è½½åˆ°ä½ æœ¬åœ°ï¼Œä¸“é—¨æŠŠä¸­æ–‡å˜æˆ 1024 ç»´å‘é‡)
print("æ­£åœ¨åŠ è½½ AI æ¨¡å‹ (ç¬¬ä¸€æ¬¡è¿è¡Œä¼šä¸‹è½½ï¼Œç¨ç­‰)...")
# âš ï¸ å¿…é¡»ç”¨è¿™ä¸ªæ¨¡å‹ï¼Œå› ä¸ºå®ƒåˆšå¥½è¾“å‡º 1024 ç»´ï¼Œå¯¹åº”ä½ æ•°æ®åº“çš„ vector(1024)
model = SentenceTransformer('BAAI/bge-large-zh-v1.5') 

def import_pdf(file_path):
    print(f"ğŸ“˜ æ­£åœ¨å¤„ç†æ–‡ä»¶: {file_path}")
    
    # --- A. è¯» PDF ---
    loader = PyPDFLoader(file_path)
    pages = loader.load()
    print(f"   âœ… è¯»åˆ°äº† {len(pages)} é¡µ")

    # --- B. åˆ‡ PDF (å…³é”®æ­¥éª¤) ---
    # chunkSize=500: æ¯å—å¤§çº¦500å­—
    # overlap=50: æ¯å—ä¹‹é—´é‡å 50å­— (é˜²æ­¢æŠŠä¸€å¥è¯åˆ‡æ–­)
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=500, 
        chunk_overlap=50
    )
    docs = text_splitter.split_documents(pages)
    print(f"   âœ… åˆ‡æˆäº† {len(docs)} ä¸ªè±†è…å—")

    # --- C. è¿æ¥æ•°æ®åº“ ---
    conn = psycopg2.connect(DB_URL)
    cur = conn.cursor()

    print("   ğŸš€ å¼€å§‹å­˜å…¥æ•°æ®åº“ (å¯èƒ½éœ€è¦ä¸€ç‚¹æ—¶é—´)...")
    
    for i, doc in enumerate(docs):
        # 1. æ‹¿åˆ°æ–‡å­—å†…å®¹
        content = doc.page_content
        # 2. æ‹¿åˆ°é¡µç  (pypdf ä» 0 å¼€å§‹ï¼Œæ‰€ä»¥æˆ‘ä»¬è¦ +1)
        page_num = doc.metadata.get('page', 0) + 1
        # 3. æ‹¿åˆ°æ–‡ä»¶å
        source_name = os.path.basename(file_path)
        
        # 4. ã€æœ€æ ¸å¿ƒã€‘æŠŠæ–‡å­—å˜æˆå‘é‡ (1024 ä¸ªæ•°å­—)
        embedding_vector = model.encode(content).tolist()
        
        # 5. æ’å…¥æ•°æ®åº“ SQL
        sql = """
            INSERT INTO knowledge_base (content, source, page_number, embedding)
            VALUES (%s, %s, %s, %s);
        """
        cur.execute(sql, (content, source_name, page_num, embedding_vector))
        
        if i % 10 == 0:
            print(f"      å·²å­˜å‚¨ {i}/{len(docs)} å—...", end="\r")

    conn.commit() # æäº¤äº‹åŠ¡
    cur.close()
    conn.close()
    print(f"\nğŸ‰ æˆåŠŸï¼ã€Š{source_name}ã€‹å·²å…¨éƒ¨å­˜å…¥çŸ¥è¯†åº“ï¼")

# --- è¿è¡Œæµ‹è¯• ---
if __name__ == "__main__":
    import_pdf("D:/winter/docs/rule.pdf")
    
    print("è¯·ä¿®æ”¹ä»£ç æœ€åä¸€è¡Œï¼Œå¡«å…¥ä½ çœŸå®çš„ PDF è·¯å¾„ï¼")