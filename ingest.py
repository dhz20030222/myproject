import os
import psycopg2
from pgvector.psycopg2 import register_vector
from dotenv import load_dotenv
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter

# ğŸ‘‡ å…³é”®ç‚¹ï¼šä» logic.py å€Ÿç”¨ get_modelï¼Œä¸è¦è‡ªå·±å† import SentenceTransformer äº†
from logic import get_model 

load_dotenv()
DB_URL = os.getenv("DATABASE_URL")

def process_uploaded_file(temp_file_path, original_filename):
    print(f"ğŸ“˜ [ä¸Šä¼ å±‚] æ­£åœ¨å¤„ç†æ–‡ä»¶: {original_filename}")
    
    try:
        # 1. è¯» PDF
        loader = PyPDFLoader(temp_file_path)
        pages = loader.load()

        # 2. åˆ‡åˆ†
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
        docs = text_splitter.split_documents(pages)

        # 3. å­˜å…¥æ•°æ®åº“
        conn = psycopg2.connect(DB_URL)
        register_vector(conn)
        cur = conn.cursor()
        
        # 4. å¾ªç¯æ’å…¥
        for doc in docs:
            content = doc.page_content
            page_num = doc.metadata.get('page', 0) + 1
            
            # ğŸ‘‡ è¿™é‡Œè°ƒç”¨ logic é‡Œçš„æ¨¡å‹æ¥ç”Ÿæˆå‘é‡
            embedding_vector = get_model().encode(content).tolist()
            
            sql = "INSERT INTO knowledge_base (content, source, page_number, embedding) VALUES (%s, %s, %s, %s)"
            cur.execute(sql, (content, original_filename, page_num, embedding_vector))

        conn.commit()
        cur.close()
        conn.close()
        
        return f"æˆåŠŸï¼ã€Š{original_filename}ã€‹å·²å…¨éƒ¨å­˜å…¥çŸ¥è¯†åº“ï¼Œå…± {len(docs)} æ¡æ•°æ®ã€‚"

    except Exception as e:
        print(f"âŒ å¤„ç†å¤±è´¥: {e}")
        raise e