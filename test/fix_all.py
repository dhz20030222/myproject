import os
import psycopg2
from pgvector.psycopg2 import register_vector # ğŸ‘ˆ å…³é”®ï¼šå¼•å…¥å‘é‡é€‚é…å™¨
from dotenv import load_dotenv
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from sentence_transformers import SentenceTransformer

# 1. åŸºç¡€é…ç½®
os.environ["HF_ENDPOINT"] = "https://hf-mirror.com" # é•œåƒåŠ é€Ÿ
load_dotenv()
DB_URL = os.getenv("DATABASE_URL")

# 2. åŠ è½½æ¨¡å‹
print("ğŸ“¥ æ­£åœ¨åŠ è½½æ¨¡å‹...")
model = SentenceTransformer('BAAI/bge-large-zh-v1.5')

def run_fix():
    print("\nğŸ§¹ æ­£åœ¨è¿æ¥æ•°æ®åº“...")
    conn = psycopg2.connect(DB_URL)
    
    # ã€æ ¸å¿ƒä¿®å¤ã€‘å‘Šè¯‰æ•°æ®åº“ï¼šè¿™æ˜¯å‘é‡ï¼Œä¸æ˜¯å­—ç¬¦ä¸²ï¼
    register_vector(conn) 
    
    cur = conn.cursor()

    # 3. æ¸…ç©ºæ—§è¡¨ï¼Œç¡®ä¿ vector(1024) ç»´åº¦æ­£ç¡®
    print("ğŸ—‘ï¸ æ¸…ç©ºæ—§æ•°æ®...")
    cur.execute("DROP TABLE IF EXISTS knowledge_base;")
    cur.execute("CREATE EXTENSION IF NOT EXISTS vector;")
    cur.execute("""
        CREATE TABLE knowledge_base (
            id SERIAL PRIMARY KEY,
            content TEXT,
            source TEXT,
            page_number INTEGER,
            embedding vector(1024) 
        );
    """)
    conn.commit()

    # 4. é‡æ–°è¯»å– PDF
    pdf_path = "D:/winter/docs/rule.pdf" # âš ï¸ ç¡®è®¤è·¯å¾„å¯¹ä¸å¯¹
    print(f"ğŸ“˜ æ­£åœ¨é‡æ–°è¯»å–: {pdf_path}")
    loader = PyPDFLoader(pdf_path)
    pages = loader.load()
    
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
    docs = text_splitter.split_documents(pages)
    print(f"âœ… åˆ‡åˆ†å®Œæˆ: å…± {len(docs)} ä¸ªç‰‡æ®µ")

    # 5. æ­£ç¡®å­˜å…¥
    print("ğŸš€ æ­£åœ¨é‡æ–°å…¥åº“ (ä½¿ç”¨æ­£ç¡®æ ¼å¼)...")
    for doc in docs:
        content = doc.page_content
        page = doc.metadata.get('page', 0) + 1
        source = os.path.basename(pdf_path)
        # ç”Ÿæˆå‘é‡
        vec = model.encode(content).tolist()
        
        # ç›´æ¥å­˜å…¥ï¼ä¸éœ€è¦æ‰‹åŠ¨è½¬ stringï¼Œé€‚é…å™¨ä¼šå¸®æˆ‘ä»¬è¦æå®š
        cur.execute(
            "INSERT INTO knowledge_base (content, source, page_number, embedding) VALUES (%s, %s, %s, %s)",
            (content, source, page, vec)
        )
    conn.commit()
    print("ğŸ‰ å…¥åº“å®Œæˆï¼")

    # 6. ç«‹å³æµ‹è¯•æœç´¢
    print("\nğŸ” æ­£åœ¨è¿›è¡Œæœ€ç»ˆæµ‹è¯•ï¼šæœç´¢ã€æœºè¯•èƒ½ä¸èƒ½ç”¨stlã€‘...")
    query = "ä¸ºè¿™ä¸ªå¥å­ç”Ÿæˆè¡¨ç¤ºä»¥ç”¨äºæ£€ç´¢ç›¸å…³æ–‡ç« ï¼šæœºè¯•èƒ½ä¸èƒ½ç”¨stl"
    q_vec = model.encode(query).tolist()
    
    # è¿™é‡Œçš„æŸ¥è¯¢ä¹Ÿå˜å¾—ç®€å•äº†ï¼Œä¸éœ€è¦ cast
    cur.execute("SELECT content, embedding <=> %s::vector FROM knowledge_base ORDER BY embedding <=> %s::vector LIMIT 3", (q_vec, q_vec))
    results = cur.fetchall()
    # æ³¨æ„ï¼šä¸¤ä¸ª %s åé¢éƒ½è¦åŠ  ::vector
    
    if len(results) > 0:
        print(f"âœ… æˆåŠŸæœåˆ° {len(results)} æ¡ç»“æœï¼")
        print(f"ğŸ“„ ç¬¬ä¸€æ¡å†…å®¹é¢„è§ˆ: {results[0][0][:50]}...")
    else:
        print("âŒ ä¾ç„¶æœä¸åˆ°... è¯·æ£€æŸ¥ PDF å†…å®¹æ˜¯å¦çœŸçš„åŒ…å«å…³é”®è¯ã€‚")

    cur.close()
    conn.close()

if __name__ == "__main__":
    run_fix()